{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14213a76",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Lab 01 Notebook: The Rosetta Frequency\n",
    "**Linguistic Forensics Investigation**\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook guides you through building a text analysis system step-by-step. Each section includes exercises, code templates, and verification steps.\n",
    "\n",
    "**Before you begin:**\n",
    "- [ ] Read [`README.md`](README.md) for the full case briefing\n",
    "- [ ] Review [`concepts.md`](concepts.md) for technical background\n",
    "- [ ] Ensure all files in `data/` are present\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 1: Field Work - Investigation\n",
    "\n",
    "### Exercise 1.1: File Reconnaissance\n",
    "\n",
    "Use terminal commands to gather intelligence on the evidence files.\n",
    "\n",
    "**Task A: File Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b21d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run these commands and record the output\n",
    "ls -lh data/\n",
    "file data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f53a74",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Record your observations:**\n",
    "- Which file is the largest?\n",
    "- What file types were detected?\n",
    "- Are all files identified as \"text\"?\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 1.2: Content Preview\n",
    "\n",
    "**Task B: Examine the first lines of each file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5007dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 5 data/english.txt\n",
    "head -n 5 data/spanish.txt\n",
    "head -n 5 data/artifact.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c86f0",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "1. What language appears to be in `english.txt`?\n",
    "2. What special characters do you notice in `spanish.txt`? (á, é, ñ?)\n",
    "3. What type of content is in `artifact.py`?\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 1.3: The Encoding Trap\n",
    "\n",
    "**Task C: Attempt to read the corrupt file**\n",
    "\n",
    "Create a file called `test_encoding.py` and add this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_encoding.py\n",
    "\n",
    "# Attempt 1: Default encoding (UTF-8)\n",
    "print(\"Attempting to read corrupt.txt with UTF-8...\")\n",
    "try:\n",
    "    with open('data/corrupt.txt', 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        print(content)\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "\n",
    "# Attempt 2: Latin-1 encoding\n",
    "print(\"\\nAttempting to read corrupt.txt with Latin-1...\")\n",
    "try:\n",
    "    with open('data/corrupt.txt', 'r', encoding='latin-1') as f:\n",
    "        content = f.read()\n",
    "        print(content)\n",
    "        print(\"SUCCESS: File read with Latin-1 encoding\")\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9eb69",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Run it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 test_encoding.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e92507",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "1. What error message did you get with UTF-8?\n",
    "2. Why did Latin-1 succeed?\n",
    "3. What does this teach you about file encoding?\n",
    "\n",
    "**Write your answers here:**\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62371a4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 2: The Build - TextAnalyzer Class\n",
    "\n",
    "### Exercise 2.1: Class Constructor\n",
    "\n",
    "Create a file called `analyzer.py` and start building the class.\n",
    "\n",
    "> **Tip for Jupyter/Colab Users:** You can use the `%%writefile analyzer.py` magic command at the very top of the code cell to automatically save your code to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d902e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer.py\n",
    "\n",
    "class TextAnalyzer:\n",
    "    \"\"\"\n",
    "    A forensic tool for analyzing text files and extracting\n",
    "    linguistic fingerprints through letter frequency analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with a file path.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to the text file to analyze\n",
    "        \"\"\"\n",
    "        # TODO: Store the filepath\n",
    "        # TODO: Initialize self.content as empty string\n",
    "        # TODO: Initialize self.frequency_map as empty dictionary\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4742fe0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Your task:** Replace `pass` with actual implementation.\n",
    "\n",
    "**Test your constructor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the bottom of analyzer.py (temporary test)\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = TextAnalyzer('data/english.txt')\n",
    "    print(f\"Filepath: {analyzer.filepath}\")\n",
    "    print(f\"Content: '{analyzer.content}'\")\n",
    "    print(f\"Frequency map: {analyzer.frequency_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc5ee9",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "```\n",
    "Filepath: data/english.txt\n",
    "Content: ''\n",
    "Frequency map: {}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2.2: File Loading Method\n",
    "\n",
    "Add the `load_file()` method to handle file reading with encoding safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339aad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(self):\n",
    "    \"\"\"\n",
    "    Load the file content with encoding detection.\n",
    "    Tries UTF-8 first, falls back to Latin-1 if needed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # TODO: Open file with UTF-8 encoding\n",
    "        # TODO: Read content into self.content\n",
    "        pass\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # TODO: Print error message\n",
    "        # TODO: Set self.content to empty string\n",
    "        pass\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        # TODO: Try again with Latin-1 encoding\n",
    "        # TODO: Read content into self.content\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e1736",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Hint:** Use `with open(...) as f:` statements.\n",
    "\n",
    "**Test your method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Test with English file\n",
    "    analyzer = TextAnalyzer('data/english.txt')\n",
    "    analyzer.load_file()\n",
    "    print(f\"Loaded {len(analyzer.content)} characters\")\n",
    "    print(f\"First 100 characters: {analyzer.content[:100]}\")\n",
    "\n",
    "    # Test with corrupt file\n",
    "    analyzer2 = TextAnalyzer('data/corrupt.txt')\n",
    "    analyzer2.load_file()\n",
    "    print(f\"\\nCorrupt file loaded: {len(analyzer2.content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34347b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 2.3: Text Cleaning Method\n",
    "\n",
    "Add the `clean_content()` method to prepare text for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(self):\n",
    "    \"\"\"\n",
    "    Clean the content by:\n",
    "    - Converting to lowercase\n",
    "    - Removing all non-alphabetic characters (keep only a-z)\n",
    "    \"\"\"\n",
    "    # TODO: Convert self.content to lowercase\n",
    "    # TODO: Filter to keep only alphabetic characters\n",
    "    # Hint: Use a list comprehension or filter with str.isalpha()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2aed4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Example approach:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: List comprehension\n",
    "cleaned = ''.join([char for char in self.content if char.isalpha()])\n",
    "\n",
    "# Option 2: Filter function\n",
    "cleaned = ''.join(filter(str.isalpha, self.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd27b2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Test your method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b00ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    analyzer = TextAnalyzer('data/english.txt')\n",
    "    analyzer.load_file()\n",
    "\n",
    "    print(f\"Before cleaning: {len(analyzer.content)} characters\")\n",
    "    print(f\"Sample: {analyzer.content[:100]}\")\n",
    "\n",
    "    analyzer.clean_content()\n",
    "\n",
    "    print(f\"\\nAfter cleaning: {len(analyzer.content)} characters\")\n",
    "    print(f\"Sample: {analyzer.content[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c474b11",
   "metadata": {},
   "source": [
    "**Expected behavior:** Numbers, punctuation, spaces removed. All lowercase.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2.4: Frequency Calculation Method\n",
    "\n",
    "Add the `calculate_frequency()` method to count letter occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(self):\n",
    "    \"\"\"\n",
    "    Count the frequency of each letter in the cleaned content.\n",
    "    Populates self.frequency_map.\n",
    "    \"\"\"\n",
    "    # TODO: Initialize frequency_map if needed\n",
    "    # TODO: Loop through each character in self.content\n",
    "    # TODO: Increment the count for each character\n",
    "    # Hint: Use frequency_map.get(char, 0) + 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5895f2d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Test your method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c885b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    analyzer = TextAnalyzer('data/english.txt')\n",
    "    analyzer.load_file()\n",
    "    analyzer.clean_content()\n",
    "    analyzer.calculate_frequency()\n",
    "\n",
    "    # Show first 10 entries\n",
    "    items = list(analyzer.frequency_map.items())[:10]\n",
    "    for letter, count in items:\n",
    "        print(f\"{letter}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d48d09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 2.5: Reporting Method\n",
    "\n",
    "Add the `report()` method to display analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f678e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(self):\n",
    "    \"\"\"\n",
    "    Print a formatted report of the analysis results.\n",
    "    Shows:\n",
    "    - Filename\n",
    "    - Total character count\n",
    "    - Top 5 most frequent letters\n",
    "    \"\"\"\n",
    "    # TODO: Calculate total characters\n",
    "    # TODO: Sort frequency_map by count (descending)\n",
    "    # TODO: Get top 5\n",
    "    # TODO: Print formatted output\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Analysis Report: {self.filepath}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Your code here\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ac453",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Hint for sorting:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_items = sorted(\n",
    "    self.frequency_map.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "top_5 = sorted_items[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439dcbf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Test your complete class:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Analyze English text\n",
    "    analyzer = TextAnalyzer('data/english.txt')\n",
    "    analyzer.load_file()\n",
    "    analyzer.clean_content()\n",
    "    analyzer.calculate_frequency()\n",
    "    analyzer.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76c548",
   "metadata": {},
   "source": [
    "**Expected output format:**\n",
    "```\n",
    "==================================================\n",
    "Analysis Report: data/english.txt\n",
    "==================================================\n",
    "Total characters: 15432\n",
    "Top 5 letters:\n",
    "  e: 1847 (11.97%)\n",
    "  t: 1234 (8.00%)\n",
    "  a: 1123 (7.28%)\n",
    "  ...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2.6: Verify with Control Samples\n",
    "\n",
    "Run your analyzer on both control samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59519fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"CONTROL SAMPLE A: English\")\n",
    "    eng = TextAnalyzer('data/english.txt')\n",
    "    eng.load_file()\n",
    "    eng.clean_content()\n",
    "    eng.calculate_frequency()\n",
    "    eng.report()\n",
    "\n",
    "    print(\"\\n\\nCONTROL SAMPLE B: Spanish\")\n",
    "    spa = TextAnalyzer('data/spanish.txt')\n",
    "    spa.load_file()\n",
    "    spa.clean_content()\n",
    "    spa.calculate_frequency()\n",
    "    spa.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafcc7e",
   "metadata": {},
   "source": [
    "**Record your findings:**\n",
    "- What are the top 3 letters in English?\n",
    "- What are the top 3 letters in Spanish?\n",
    "- How are they different?\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 3: Critical Incident - CodeAnalyzer\n",
    "\n",
    "### Exercise 3.1: Analyze the Artifact (Before Cleaning)\n",
    "\n",
    "First, run the standard `TextAnalyzer` on the artifact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"MYSTERY ARTIFACT (Standard Analysis):\")\n",
    "    artifact = TextAnalyzer('data/artifact.py')\n",
    "    artifact.load_file()\n",
    "    artifact.clean_content()\n",
    "    artifact.calculate_frequency()\n",
    "    artifact.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c70474",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "1. What are the top 5 letters?\n",
    "2. Do they match English or Spanish patterns?\n",
    "3. Why might the results be misleading?\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 3.2: Build the CodeAnalyzer Subclass\n",
    "\n",
    "Add this new class to `analyzer.py` (AFTER the TextAnalyzer class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # Add at top of file\n",
    "\n",
    "class CodeAnalyzer(TextAnalyzer):\n",
    "    \"\"\"\n",
    "    Specialized analyzer for source code files.\n",
    "    Inherits from TextAnalyzer but overrides cleaning logic\n",
    "    to remove programming-specific noise.\n",
    "    \"\"\"\n",
    "\n",
    "    def clean_content(self):\n",
    "        \"\"\"\n",
    "        Clean source code by removing:\n",
    "        - Comments (# to end of line)\n",
    "        - Common Python keywords\n",
    "        - Syntax characters\n",
    "        Then apply standard text cleaning.\n",
    "        \"\"\"\n",
    "        # TODO: Remove comments using regex\n",
    "        # Pattern: r'#.*' removes from # to end of line\n",
    "\n",
    "        # TODO: Remove Python keywords\n",
    "        # Pattern: r'\\b(def|class|return|import|if|else|for|while|self)\\b'\n",
    "\n",
    "        # TODO: Remove common syntax characters\n",
    "        # You can remove: _ ( ) : \" '\n",
    "\n",
    "        # TODO: Apply the standard cleaning (lowercase, alpha only)\n",
    "        # Hint: You can call the parent method or reuse the logic\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b519941",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Implementation hints:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove comments\n",
    "self.content = re.sub(r'#.*', '', self.content)\n",
    "\n",
    "# Remove keywords\n",
    "keywords = r'\\b(def|class|return|import|if|else|for|while|self|try|except|print|with|as|in|from)\\b'\n",
    "self.content = re.sub(keywords, '', self.content)\n",
    "\n",
    "# Remove syntax characters\n",
    "for char in ['_', '(', ')', ':', '\"', \"'\", '{', '}', '[', ']']:\n",
    "    self.content = self.content.replace(char, ' ')\n",
    "\n",
    "# Apply standard cleaning (lowercase, alpha only)\n",
    "self.content = self.content.lower()\n",
    "self.content = ''.join(char for char in self.content if char.isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8098d7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 3.3: Analyze the Artifact (After Specialized Cleaning)\n",
    "\n",
    "Test your new analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9628bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"MYSTERY ARTIFACT (Code Analysis):\")\n",
    "    artifact = CodeAnalyzer('data/artifact.py')\n",
    "    artifact.load_file()\n",
    "    artifact.clean_content()\n",
    "    artifact.calculate_frequency()\n",
    "    artifact.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7dacd7",
   "metadata": {},
   "source": [
    "**Compare results:**\n",
    "- What are the top 5 letters now?\n",
    "- Do they match English or Spanish patterns better?\n",
    "- What changed compared to standard analysis?\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 3.4: The Revelation\n",
    "\n",
    "**Final Investigation Questions:**\n",
    "\n",
    "1. **Language Identification:** Based on letter frequency, what language is the artifact written in?\n",
    "\n",
    "2. **Evidence:** What specific frequency patterns support your conclusion?\n",
    "\n",
    "3. **Inheritance Justification:** Why was inheritance useful here? Could you have achieved the same result without creating a subclass?\n",
    "\n",
    "**Write your forensic report:**\n",
    "\n",
    "```\n",
    "FORENSIC REPORT: ARTIFACT.PY\n",
    "\n",
    "Analysis Date: [Today's Date]\n",
    "Analyst: [Your Name]\n",
    "\n",
    "FINDINGS:\n",
    "The mystery artifact exhibits the following linguistic characteristics:\n",
    "- Top 5 letters: [list them]\n",
    "- Frequency pattern matches: [English/Spanish]\n",
    "\n",
    "CONCLUSION:\n",
    "The artifact was authored by an individual who speaks [LANGUAGE] because\n",
    "[explain your reasoning based on frequency analysis].\n",
    "\n",
    "TECHNICAL NOTE:\n",
    "The use of inheritance was essential because [explain why CodeAnalyzer\n",
    "needed to override clean_content() while reusing other methods].\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 4: Integration and Submission\n",
    "\n",
    "### Exercise 4.1: Create main.py\n",
    "\n",
    "Create a file called `main.py` that runs all analyses.\n",
    "\n",
    "> **Tip for Jupyter/Colab Users:** You can use the `%%writefile main.py` magic command at the top of the cell to generate the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\"\"\"\n",
    "Main execution script for Lab 01: The Rosetta Frequency\n",
    "Runs analysis on all evidence files.\n",
    "\"\"\"\n",
    "\n",
    "from analyzer import TextAnalyzer, CodeAnalyzer\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\" COMP3084 - Lab 01: Linguistic Forensics Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "\n",
    "    # Analyze English control\n",
    "    print(\"CONTROL SAMPLE A: English Literature\")\n",
    "    print(\"-\" * 70)\n",
    "    eng = TextAnalyzer('data/english.txt')\n",
    "    eng.load_file()\n",
    "    eng.clean_content()\n",
    "    eng.calculate_frequency()\n",
    "    eng.report()\n",
    "    print()\n",
    "\n",
    "    # Analyze Spanish control\n",
    "    print(\"CONTROL SAMPLE B: Spanish Literature\")\n",
    "    print(\"-\" * 70)\n",
    "    spa = TextAnalyzer('data/spanish.txt')\n",
    "    spa.load_file()\n",
    "    spa.clean_content()\n",
    "    spa.calculate_frequency()\n",
    "    spa.report()\n",
    "    print()\n",
    "\n",
    "    # Analyze artifact with standard analyzer\n",
    "    print(\"MYSTERY ARTIFACT: Standard Text Analysis\")\n",
    "    print(\"-\" * 70)\n",
    "    artifact_text = TextAnalyzer('data/artifact.py')\n",
    "    artifact_text.load_file()\n",
    "    artifact_text.clean_content()\n",
    "    artifact_text.calculate_frequency()\n",
    "    artifact_text.report()\n",
    "    print()\n",
    "\n",
    "    # Analyze artifact with code analyzer\n",
    "    print(\"MYSTERY ARTIFACT: Specialized Code Analysis\")\n",
    "    print(\"-\" * 70)\n",
    "    artifact_code = CodeAnalyzer('data/artifact.py')\n",
    "    artifact_code.load_file()\n",
    "    artifact_code.clean_content()\n",
    "    artifact_code.calculate_frequency()\n",
    "    artifact_code.report()\n",
    "    print()\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\" Analysis Complete\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da43a0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Run the complete analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2588d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991a43f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 4.2: Document Your Work\n",
    "\n",
    "Create a file called `submission.md` with the following sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d02ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "# Lab 01 Submission: The Rosetta Frequency\n",
    "\n",
    "**Student Name:** [Your Name]\n",
    "**Student ID:** [Your ID]\n",
    "**Date:** [Submission Date]\n",
    "\n",
    "---\n",
    "\n",
    "## Section A: Phase 1 Observations\n",
    "\n",
    "### File Inspection\n",
    "[Paste your ls -lh and file command outputs]\n",
    "\n",
    "### Encoding Investigation\n",
    "[Describe the error you encountered with corrupt.txt and explain why it occurred]\n",
    "\n",
    "---\n",
    "\n",
    "## Section B: Phase 2 Analysis Results\n",
    "\n",
    "### English Control Sample\n",
    "- Top 5 letters: [list with percentages]\n",
    "- Total characters analyzed: [number]\n",
    "\n",
    "### Spanish Control Sample\n",
    "- Top 5 letters: [list with percentages]\n",
    "- Total characters analyzed: [number]\n",
    "\n",
    "### Comparison\n",
    "[Describe the key differences between English and Spanish frequency patterns]\n",
    "\n",
    "---\n",
    "\n",
    "## Section C: Phase 3 Critical Incident\n",
    "\n",
    "### Standard Analysis of Artifact\n",
    "- Top 5 letters: [list]\n",
    "\n",
    "### Code Analysis of Artifact\n",
    "- Top 5 letters: [list]\n",
    "\n",
    "### Conclusion\n",
    "[State which language the artifact is written in and provide evidence]\n",
    "\n",
    "### Inheritance Justification\n",
    "[Explain why creating a CodeAnalyzer subclass was the right design choice]\n",
    "\n",
    "---\n",
    "\n",
    "## Section D: AI Usage Appendix (if applicable)\n",
    "\n",
    "**Did you use AI tools? [Yes/No]**\n",
    "\n",
    "If yes, complete the following for each significant AI interaction:\n",
    "\n",
    "### Interaction 1\n",
    "- **Tool Used:** [e.g., ChatGPT, GitHub Copilot]\n",
    "- **Methodology:** [What problem were you solving?]\n",
    "- **The Prompt:** [Copy your query]\n",
    "- **The Output:** [Summarize AI's response]\n",
    "- **Human Value-Add:** [What did you change, verify, or correct?]\n",
    "\n",
    "[Repeat for additional interactions]\n",
    "\n",
    "---\n",
    "\n",
    "## Section E: Reflection\n",
    "\n",
    "1. What was the most challenging part of this lab?\n",
    "2. What did you learn about object-oriented programming?\n",
    "3. How does letter frequency analysis relate to real-world applications?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff381bb4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Verification Checklist\n",
    "\n",
    "Before submitting, ensure:\n",
    "\n",
    "- [ ] `analyzer.py` contains both `TextAnalyzer` and `CodeAnalyzer` classes\n",
    "- [ ] `main.py` runs without errors\n",
    "- [ ] All four evidence files are analyzed\n",
    "- [ ] `submission.md` is complete with all sections\n",
    "- [ ] If AI was used, it is properly documented\n",
    "- [ ] You can explain every line of code you wrote\n",
    "\n",
    "---\n",
    "\n",
    "## Bonus Challenge (+10 points)\n",
    "\n",
    "Implement an automatic language detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(self):\n",
    "    \"\"\"\n",
    "    Automatically detect if the text is English or Spanish\n",
    "    by comparing frequency patterns to reference distributions.\n",
    "\n",
    "    Returns:\n",
    "        str: 'English', 'Spanish', or 'Unknown'\n",
    "    \"\"\"\n",
    "    # Reference: In English, 'e' is most common\n",
    "    # Reference: In Spanish, 'e' and 'a' are nearly equal, with 'a' often higher\n",
    "\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef72031",
   "metadata": {},
   "source": [
    "Add this method to `TextAnalyzer` and test it on your control samples.\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the Rosetta Frequency investigation. You've learned how to:\n",
    "- Build reusable classes with encapsulation\n",
    "- Handle file I/O with encoding safety\n",
    "- Use inheritance to specialize behavior\n",
    "- Apply data structures (dictionaries) for analysis\n",
    "- Think like a forensic data scientist\n",
    "\n",
    "**Next Steps:** Review your code, ensure it's well-documented, and submit through the course portal.\n",
    "\n",
    "---\n",
    "\n",
    "**End of Notebook**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
